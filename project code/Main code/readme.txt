Code present in this folder was used to webscrape all the data for model training.
then the data was preprocessed
finally the model was trained locally using the roberta base model
but RoBERTa Large model was finally trained on Google Collab and used GPU T4(15GB) for GPU accelerated support
